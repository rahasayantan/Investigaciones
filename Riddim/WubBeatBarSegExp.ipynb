{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Given two percussion loops, can we compute the offsets at which they can be mixed to yield the most phase, rhythmic and musical sum?\n",
    "* As one loop slides over the other, doing a mix at each time step, which one of these mixes is the best?\n",
    "* What does a mixing train-wreck look like?\n",
    "\n",
    "\n",
    "* If we use synthesized audio loops at a given tempo, then a convolutional or denoising autoencoder to generate features, like onsets or beats, how good are those features versus say SuperFlux?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kick_sample_path = \"/Users/iorife/github/Investigaciones/Drums/Kick/Kick3kDeep.wav\"\n",
    "#kick_sample_path = \"/Users/iorife/github/Investigaciones/Drums/Kick/Kick 90s 1.wav\"\n",
    "\n",
    "kick_sample, sr = librosa.load(kick_sample_path, mono=True, sr=48000)\n",
    "print(\"Len of samples: \" + str(len(kick_sample)))\n",
    "print(\"Sample rate: \" + str(sr))\n",
    "y = createFourOnTheFloor(bpm=128, nb_beats=32, sr=sr, sample=kick_sample)\n",
    "librosa.output.write_wav(\"4-on-floor-output.wav\", y, sr)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "librosa.display.waveplot(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remix_analysis = ['meta', 'id', 'md5',                                 # administrative\n",
    "                  'duration', 'loudness',                              # singleton props of file\n",
    "                  'time_signature', 'time_signature_confidence',       # time, key sigs + their confidence  \n",
    "                  'key', 'key_confidence',\n",
    "                  'tempo', 'tempo_confidence',                         # tempo + confidence\n",
    "                  'bars', 'beats', 'sections', 'tatums', 'segments']   # remixing meat\n",
    "\n",
    "librosa_remix = {}\n",
    "\n",
    "# analysis params! no hardcoding!\n",
    "hop_length = 32\n",
    "fftsize = 1024\n",
    "\n",
    "print(\"Hopsize in ms: \" + str(float(hop_length)/float(sr)))\n",
    "print(\"FFTsize in ms: \" + str(float(fftsize)/float(sr)))\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# duration\n",
    "librosa_remix['duration'] = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# loudness\n",
    "linear_rms = np.sqrt(np.mean(np.square(y)))\n",
    "dB_rms = 20 * np.log10((1e-20 + linear_rms))\n",
    "librosa_remix['loudness'] = dB_rms\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# percussive - harmonic separation\n",
    "D = librosa.stft(y, hop_length=hop_length)\n",
    "D_harm, D_perc = librosa.decompose.hpss(D)\n",
    "y_perc = librosa.istft(D_perc, hop_length=hop_length)\n",
    "y_perc = y_perc / np.max(np.abs(y_perc), axis=0)\n",
    "\n",
    "print(\"Len y:      \" + str(len(y)))\n",
    "print(\"Len y_perc: \" + str(len(y_perc)))\n",
    "plt.figure(figsize=(12, 6))\n",
    "librosa.display.waveplot(y=y_perc, sr=sr)\n",
    "\n",
    "# n = len(y)\n",
    "# y_pad = librosa.util.fix_length(y, n + fftsize // 2)\n",
    "# D = librosa.stft(y_pad, n_fft=n_fft)\n",
    "# y_out = librosa.util.fix_length(librosa.istft(D), n)\n",
    "# np.max(np.abs(y - y_out))\n",
    "\n",
    "# y = y_perc\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# tempo\n",
    "librosa_tempo, librosa_beat_frames = librosa.beat.beat_track(y, sr, hop_length=hop_length)\n",
    "librosa_remix['tempo'] = librosa_tempo\n",
    "librosa_remix['tempo_confidence'] = 1.0\n",
    "print \"librosa tempo is: \", librosa_remix['tempo']\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# key\n",
    "# Longer FFT window to better resolve low frequencies\n",
    "C = librosa.feature.chromagram(y=y, sr=sr, n_fft=fftsize, hop_length=hop_length)\n",
    "p_classes = ['A', 'A#', 'B', 'C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#']\n",
    "p_class_counts = []\n",
    "\n",
    "# let's find the average chroma value\n",
    "mean = C.mean()\n",
    "for p_class_name, values in zip(p_classes, C):\n",
    "    count = (values > mean).sum()\n",
    "    p_class_counts.append(count)\n",
    "    \n",
    "key_index = p_class_counts.index(max(p_class_counts))\n",
    "key = p_classes[key_index]\n",
    "\n",
    "# map key into echonest format [C, C#, D, Eb, E, F, F#, G, Ab, A, Bb, B]\n",
    "librosa_remix['key'] = (key_index - 3) % 12\n",
    "librosa_remix['key_confidence'] = 1.0\n",
    "print \"librosa key is: \", key, key_index\n",
    "print \"mapped -> echonest key is: \", librosa_remix['key'] \n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# librosa beats\n",
    "librosa_beats = librosa.frames_to_time(librosa_beat_frames, sr, hop_length=hop_length)\n",
    "\n",
    "# plot BEAT distributions!\n",
    "print(\"Num beats: \" + str(len(librosa_beats)))\n",
    "print(\"Beat times: \" + str(librosa_beats))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.diff(librosa_beats)\n",
    "print(x)\n",
    "bins = np.linspace(0.4, .5, 200)\n",
    "plt.hist(x, bins, alpha=0.5, label='librosa diff start')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Signature experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.linalg as la    # import numpy linear algebra module\n",
    "import scipy.spatial as spt  # import scipy spatial module\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "def compute_squared_EDM_method1(X):\n",
    "    \n",
    "    # determine dimensions of data matrix X\n",
    "    m,n = X.shape\n",
    "    \n",
    "    # initialize squared EDM D\n",
    "    D = np.zeros((n,n))\n",
    "    \n",
    "    # iterate over upper triangle of D\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            D[i,j] = la.norm(X[:,i] - X[:,j])**2\n",
    "            D[j,i] = D[i,j]\n",
    "    return D\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "def compute_squared_EDM_method4(X):\n",
    "    \n",
    "    # determine dimensions of data matrix X\n",
    "    m,n = X.shape\n",
    "    \n",
    "    # determine dimensions of data matrix X m,n = X.shape\n",
    "    # compute Gram matrix G\n",
    "    G = np.dot(X.T, X)\n",
    "    \n",
    "    # compute matrix H\n",
    "    H = np.tile(np.diag(G), (n,1))\n",
    "    return H + H.T - 2*G\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "def compute_squared_EDM_method5(X):\n",
    "    V = spt.distance.pdist(X.T, 'sqeuclidean')\n",
    "    return spt.distance.squareform(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# L == window length == (1/32) the duration a beat\n",
    "#L = int( np.median(np.diff(librosa_beats)) * sr * (1.0/32.0))\n",
    "tempo = 123.0\n",
    "\n",
    "sample_rate = 44100\n",
    "L = int( ( 60.0 / tempo ) * sample_rate * (1.0 / 32.0) )\n",
    "\n",
    "# H == hop_length == (1/2) L\n",
    "H = int(L * 0.5)\n",
    "\n",
    "print \"Window length: \" + str(int(L)) + \"  Hop length: \" + str(int(H))\n",
    "\n",
    "# Maximum bar length == 60 / 60  bpm * 12 beats = 12 seconds (12/4 time @ 60 bpm)\n",
    "# Minimum bar length == 60 / 200 bpm * 02 beats = .6 seconds (2/4 time @ 200 bpm)\n",
    "\n",
    "# start of first beat and read in N=4 seconds\n",
    "# first_beat = librosa_beats[0]\n",
    "first_beat = .985 # IO HAVOC --- OVERRIDE!!!\n",
    "first_beat = .127\n",
    "\n",
    "filenameAlt = \"./test-audio/Bentos_RRReshape_snippet.wav\"\n",
    "yy, sr = librosa.load(filenameAlt, sr=None, offset=first_beat, duration=8.0)\n",
    "D = librosa.stft(yy, n_fft=L, hop_length=H)\n",
    "S, P = librosa.magphase(D)\n",
    "\n",
    "# Cosine similarity (dot product)\n",
    "# ASMatrix = np.dot(S.T, S)\n",
    "\n",
    "# Squared euclidean \n",
    "ASMatrix = compute_squared_EDM_method5(S)\n",
    "print \"Similarity matrix shape: \" + str(ASMatrix.shape)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.pcolor(ASMatrix, cmap=plt.cm.ocean)\n",
    "plt.colorbar()\n",
    "plt.axes().set_aspect(1.0/plt.axes().get_data_ratio())\n",
    "plt.show()\n",
    "\n",
    "print np.argmax(ASMatrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def grabDiag(a, offset):\n",
    "    altdiag = np.diag(np.rot90(a), k=offset)\n",
    "    return altdiag[::-1] \n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))\n",
    "\n",
    "def computeSqrtSumSq(components):\n",
    "#   print len(components)\n",
    "    retval = np.sqrt(np.sum(np.square(components) / len(components), axis=0))\n",
    "    return retval\n",
    "\n",
    "# print grabDiag(a, 0)\n",
    "# print grabDiag(a, 1)\n",
    "# print grabDiag(a, 2)\n",
    "# print grabDiag(a, 3)\n",
    "# print grabDiag(a, 4)\n",
    "# print grabDiag(a, 5)\n",
    "# print grabDiag(a, 6)\n",
    "\n",
    "# iterate through all bar lengths (i.e. num beats in Bar)\n",
    "# components/beat is fixed at 1:64, so we're really wondering \n",
    "# components per bar, assuming that we start on the first beat (no inter-beat offset)\n",
    "# and with the prior that the beats make up bars and the highest similarity is on the beat\n",
    "\n",
    "SM = []\n",
    "for beatsInBar in xrange(2, 13):\n",
    "    componentsInBar = beatsInBar * 64\n",
    "    print \"Beats in bar: \" + str(beatsInBar) + \"  Components in bar: \"+ str(componentsInBar)\n",
    "    \n",
    "    SCS_sum = 0\n",
    "    SIS_sum = 0\n",
    "    \n",
    "    eqBar = componentsInBar\n",
    "    eqR = 0\n",
    "    eqSc = 0\n",
    "    eqSi = 0\n",
    "    \n",
    "    # IO HAVOC -- what are we doing here, we need to grab diags on componentsInBar * j (on the beat components)\n",
    "    # how many diagonals do we have?? depends on the len\n",
    "    numDiags = ASMatrix.shape[0] / componentsInBar\n",
    "    print \"numDiags: \" + str(numDiags)\n",
    "    for diag in xrange(0, numDiags):\n",
    "        \n",
    "        currDiag = grabDiag(ASMatrix, componentsInBar + diag * componentsInBar)\n",
    "        print  \"Diag: \" + str(diag) + \" @ xpos - component #: \" + str(componentsInBar + diag * componentsInBar)\n",
    "        \n",
    "        # split array to compute similarity: SCS (complete bars) and SIS (incomplete bars)\n",
    "        splitarrs = [np.array(chunk) for chunk in chunker(currDiag, componentsInBar)]\n",
    "\n",
    "        # save off the length of the        \n",
    "        eqR = len(splitarrs[-1])\n",
    "        \n",
    "        # compute per diagonal SCS & SIS\n",
    "        for arr in splitarrs[:-1]:\n",
    "            temp = computeSqrtSumSq(arr)\n",
    "            print \"SCS len: \" + str(len(arr)) + \"  SCS: \" + str(temp)\n",
    "            SCS_sum += temp\n",
    "            eqSc += 1\n",
    "        else:\n",
    "            temp = computeSqrtSumSq(splitarrs[-1]) \n",
    "            print \"SIS len: \" + str(len(splitarrs[-1])) + \"  SIS: \" + str(temp)\n",
    "            SIS_sum += temp\n",
    "            eqSi += 1\n",
    "        \n",
    "        print \"  \"\n",
    "        \n",
    "        peaks = np.zeros(len(currDiag))\n",
    "        mx = np.max(currDiag)\n",
    "        # make a mask to track componentsInBar components\n",
    "        for i in xrange(0, len(currDiag)):\n",
    "            if i % componentsInBar == 0:\n",
    "                peaks[i] = mx\n",
    "\n",
    "        print  \"Diag: \" + str(diag) + \" @ xpos - component #: \" + str(componentsInBar + diag * componentsInBar)\n",
    "        x1 = np.linspace(0, len(currDiag), len(currDiag), endpoint=True)\n",
    "\n",
    "        fig = plt.figure(figsize = (20, 7))\n",
    "        plt.plot(x1, currDiag)\n",
    "        plt.plot(x1, peaks, 'o-', label='peaks')\n",
    "\n",
    "        plt.axes().set_autoscale_on(True)\n",
    "        plt.axes().autoscale_view(True, True, False)\n",
    "        plt.axes().set_ylabel(str(diag) + \"  \" + str(componentsInBar))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    print \"Bar: \" + str(eqBar) + \"  r: \" + str(eqR) + \"  Sc: \" + str(eqSc) + \"  Si: \" +  str(eqSi)\n",
    "    SM.append((beatsInBar*SCS_sum +  eqR*SIS_sum)/( (eqBar*eqSc) +  (eqR*eqSi)))\n",
    "#     SM.append((beatsInBar * SCS_sum + eqR * SIS_sum)/ 1.0 )\n",
    "\n",
    "    print \"SCS sum: \" + str(SCS_sum) + \"  SIS_sum: \" + str(SIS_sum)\n",
    "    print \"\\n\"\n",
    "print SM\n",
    "    \n",
    "    \n",
    "# beatsInBar = 2\n",
    "# componentsInBar = beatsInBar * 64    \n",
    "# diagNum = 0   \n",
    "# diagToPlot = grabDiag(ASMatrix, diagNum)\n",
    "# print \"ASMatrix diagonal #\" + str(diagNum) + \" has length: \" + str(len(diagToPlot))\n",
    "\n",
    "# # split array to compute similarity measures: \n",
    "# # SCS (complete bars) and SIS (incomplete bars)\n",
    "# splitarrs = []\n",
    "# for chunk in chunker(diagToPlot, componentsInBar):\n",
    "#     splitarrs.append(np.array(chunk))\n",
    "\n",
    "# # s = np.array(splitarrs)\n",
    "# # for x in splitarrs:\n",
    "# #     print len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(SM)\n",
    "plt.axes().set_aspect(1.0/plt.axes().get_data_ratio())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(yy)\n",
    "plt.axes().set_aspect(1.0/plt.axes().get_data_ratio())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# iroro zoom in on one \"beatsInBar\" hypothesis at a time\n",
    "############################################################\n",
    "\n",
    "beatsInBar = 2\n",
    "componentsInBar = beatsInBar * 64  \n",
    "\n",
    "print \"Beats in bar: \" + str(beatsInBar) + \"  Components in bar: \"+ str(componentsInBar)\n",
    "    \n",
    "    \n",
    "# IO HAVOC -- what are we doing here, we need to grab diags on componentsInBar * j (on the beat components)\n",
    "# how many diagonals do we have?? depends on the len\n",
    "numDiags = ASMatrix.shape[0] / (componentsInBar)\n",
    "print \"numDiags: \" + str(numDiags)\n",
    "for diag in xrange(0, numDiags):\n",
    "    currDiag = grabDiag(ASMatrix, componentsInBar + diag * componentsInBar)\n",
    "    peaks = np.zeros(len(currDiag))\n",
    "\n",
    "    mx = 20000# np.max(currDiag)\n",
    "    # make a mask to track componentsInBar components\n",
    "    for i in xrange(0, len(currDiag)):\n",
    "        if i % componentsInBar == 0:\n",
    "            peaks[i] = mx\n",
    "            \n",
    "    print  \"Diag: \" + str(diag) + \" @ xpos - component #: \" + str(componentsInBar + diag * componentsInBar)\n",
    "    x1 = np.linspace(0, len(currDiag), len(currDiag), endpoint=True)\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 7))\n",
    "    plt.plot(x1, currDiag)\n",
    "    plt.plot(x1, peaks, 'o-', label='peaks')\n",
    "    \n",
    "    plt.axes().set_autoscale_on(True)\n",
    "    plt.axes().autoscale_view(True, True, False)\n",
    "    plt.axes().set_ylabel(str(diag) + \"  \" + str(componentsInBar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))\n",
    "\n",
    "beatsInBar = 2\n",
    "componentsInBar = beatsInBar * 64    \n",
    "diagNum = 0   \n",
    "currDiag = grabDiag(ASMatrix, diagNum)\n",
    "print \"ASMatrix diagonal #\" + str(diagNum) + \" has length: \" + str(len(currDiag))\n",
    "\n",
    "\n",
    "# split array to compute similarity measures: \n",
    "# SCS (complete bars) and SIS (incomplete bars)\n",
    "print len(currDiag), componentsInBar\n",
    "splitarrs = []\n",
    "for chunk in chunker(currDiag, componentsInBar):\n",
    "    splitarrs.append(np.array(chunk))\n",
    "\n",
    "s = np.array(splitarrs)\n",
    "for x in splitarrs:\n",
    "    print len(x)\n",
    "\n",
    "# fig = plt.figure(figsize = (20, 7))\n",
    "# x1 = np.linspace(0, len(diagToPlot), len(diagToPlot), endpoint=True)\n",
    "# plt.plot(x1, diagToPlot)\n",
    "# plt.axes().set_autoscale_on(True)\n",
    "# plt.axes().autoscale_view(True, True, False)\n",
    "# plt.axes().set_ylabel('diag') \n",
    "# plt.axes().fill_between(x1, diagToPlot, 0, where=x1 < componentsInBar, facecolor='green', interpolate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\begin{align}\n",
    "{C} = \\textrm{Components in Bar}\\\\\n",
    "SCS = \\sqrt{ \\frac{\\displaystyle\\sum_{i=1}^{C} G_i^2}{C} } \\\\\n",
    "\\\\\n",
    "SIS = \\sqrt{ \\frac{\\displaystyle\\sum_{i=1}^{r} P_i^2 }{r} }\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amp = 20 * np.log10(0.2)\n",
    "print amp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
